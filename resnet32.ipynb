{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet32.ipynb","provenance":[{"file_id":"1DDNGJY14blLIMdZPpZ6__pEiWmS7MEqy","timestamp":1588617321456}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"mount_file_id":"18jlB0hTtH5OG0TufQly1SzA9Vzn0-lCB","authorship_tag":"ABX9TyOehtmdF1ythQddnGnKuxAw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tFdwc5SlKGC8","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","\n","import matplotlib.pyplot as plt\n","\n","BN_GAMMA = 0.01\n","class ResNetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResNetBlock, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.shortcut_is_needed = in_channels == out_channels\n","        if in_channels == out_channels:\n","            self.shortcut = nn.Identity()\n","            stride = 1\n","        else:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=(2, 2), stride=(2, 2), bias=False),\n","                nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False)\n","                                          )\n","            stride = 2\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=(1, 1), bias=False),\n","            nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=(1, 1), bias=False),\n","            nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False)\n","        )\n","        self.relu = nn.ReLU()\n","\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        return self.relu(self.block(x) + residual)\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, N=5):\n","        super(ResNet, self).__init__()\n","        layers = [nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","        layers += [ResNetBlock(16, 16)] * N\n","        layers += [ResNetBlock(16, 32)] + [ResNetBlock(32, 32)] * (N - 1)\n","        layers += [ResNetBlock(32, 64)] + [ResNetBlock(64, 64)] * (N - 1)\n","        layers += [nn.AvgPool2d((8, 8))]\n","        self.decoder = nn.Linear(64, 10)\n","        self.layers = nn.Sequential(\n","            *layers\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = x.view(x.size(0), -1)\n","        return self.decoder(x)\n","\n","dummy = torch.ones((1, 3, 32, 32))\n","transform = transforms.Compose(\n","        [\n","            transforms.Pad((4, 4)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop(32),\n","            transforms.ToTensor()\n","        ]\n","    )\n","model = ResNet(N=5)\n","trainset = torchvision.datasets.CIFAR10(\"CIFAR\", train=True, download=True, transform=transform)\n","dl = DataLoader(trainset, batch_size=32, shuffle=True)\n","\n","print(model)\n","#print(model(dummy).shape)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","CUDA = torch.cuda.device_count()\n","print(torch.cuda.get_device_name(0))\n","print(torch.cuda.memory_summary(device=0))\n","print(torch.cuda.max_memory_allocated(device=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpbjNpAuKSj-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQytZjRAMFAn","colab_type":"code","colab":{}},"source":["mean_train_losses = []\n","mean_test_losses = []\n","test_acc_list = []\n","BS = 200\n","trainset = torchvision.datasets.CIFAR10(\"CIFAR\", train=True, download=False, transform=transform)\n","dl = DataLoader(trainset, batch_size=BS, shuffle=True)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","epochs = 0\n","epoch = 0\n","if True:\n","    \n","    images, labels = iter(dl).next()\n","\n","    device = 'cuda'\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    \n","    model.to(device)\n","\n","    print(images.element_size())\n","    print(labels.element_size())\n","    \n","    accuracy = 0\n","    while accuracy < 100:\n","        epoch += 1\n","        model.train()\n","\n","        train_losses = []\n","        test_losses = []\n","\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        print(\"outpus size\", outputs.element_size())\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_losses.append(loss.item())\n","\n","        correct = 0\n","        total = 0\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","        mean_train_losses.append(np.mean(train_losses))\n","\n","        accuracy = 100 * correct / total\n","        test_acc_list.append(accuracy)\n","        print('epoch : {}, train loss : {:.4f}, test loss : {:.4f}, test acc : {:.2f}%' \\\n","              .format(epoch + 1, np.mean(train_losses), np.mean(test_losses), accuracy))\n","\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n","    ax1.plot(mean_train_losses, label='train')\n","    #ax1.plot(mean_test_losses, label='test')\n","    lines, labels = ax1.get_legend_handles_labels()\n","    ax1.legend(lines, labels, loc='best')\n","\n","    ax2.plot(test_acc_list, label='test acc')\n","    ax2.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2b4kqU6MfYZK","colab_type":"code","colab":{}},"source":["TRAIN = False\n","if True:\n","    mean_train_losses = []\n","    mean_test_losses = []\n","    test_acc_list = []\n","    train_acc_list = []\n","    BS = 256\n","    trainset = torchvision.datasets.CIFAR10(\"CIFAR\", train=True, download=False, transform=transform)\n","    train_loader = DataLoader(trainset, batch_size=BS, shuffle=True)\n","    testset = torchvision.datasets.CIFAR10(\"CIFAR\", train=False, download=False, transform=transform)\n","    test_loader = DataLoader(trainset, batch_size=BS, shuffle=False)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n","    epochs = 200\n","    best_acc = 0\n","    PATH=\"drive/My Drive/resne32_t.pt\"\n","    #torch.save(model, PATH)\n","    #print(f\"Model was dumped to {PATH}\")\n","    \n","    model = torch.load(PATH)\n","    model.eval()\n","    print(\"train started\")\n","    if CUDA:\n","      device = 'cuda'\n","      model.to(device)\n","    for epoch in range(epochs):\n","\n","        if TRAIN:\n","          model.train()\n","        \n","        \n","          correct = 0\n","          total = 0\n","          train_losses = []\n","          test_losses = []\n","\n","          for i, (images, labels) in enumerate(train_loader):\n","\n","              if CUDA:\n","                  images = images.to(device)\n","                  labels = labels.to(device)\n","                  \n","              optimizer.zero_grad()\n","\n","              outputs = model(images)\n","\n","              _, predicted = torch.max(outputs.data, 1)\n","              correct += (predicted == labels).sum().item()\n","              total += labels.size(0)\n","              \n","\n","              loss = loss_fn(outputs, labels)\n","              loss.backward()\n","              optimizer.step()\n","\n","              train_losses.append(loss.item())\n","\n","          t_accuracy = 100 * correct / total\n","          train_acc_list.append(t_accuracy)\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for i, (images, labels) in enumerate(test_loader):\n","                if CUDA:\n","                  images = images.to(device)\n","                  labels = labels.to(device)\n","\n","                outputs = model(images)\n","                loss = loss_fn(outputs, labels)\n","\n","                test_losses.append(loss.item())\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                correct += (predicted == labels).sum().item()\n","                total += labels.size(0)\n","\n","        mean_train_losses.append(np.mean(train_losses))\n","        mean_test_losses.append(np.mean(test_losses))\n","\n","        accuracy = 100 * correct / total\n","        test_acc_list.append(accuracy)\n","        if accuracy>best_acc:\n","            torch.save(model, PATH)\n","            best_acc = accuracy\n","            print(f\"Model was dumped to {PATH}\")\n","        print('epoch : {}, train loss : {:.4f}, test loss : {:.4f}, train acc : {:.2f}%, test acc : {:.2f}%' \\\n","              .format(epoch + 1, np.mean(train_losses), np.mean(test_losses),t_accuracy, accuracy))\n","\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n","    ax1.plot(mean_train_losses, label='train')\n","    ax1.plot(mean_test_losses, label='test')\n","    lines, labels = ax1.get_legend_handles_labels()\n","    ax1.legend(lines, labels, loc='best')\n","\n","\n","    ax2.plot(train_acc_list, label='train acc')\n","    ax2.plot(test_acc_list, label='test acc')\n","    ax2.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAzwSHK-cJN-","colab_type":"code","colab":{}},"source":["if True:\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n","    ax1.plot(mean_train_losses, label='train')\n","    ax1.plot(mean_test_losses, label='test')\n","    lines, labels = ax1.get_legend_handles_labels()\n","    ax1.legend(lines, labels, loc='best')\n","\n","    ax2.plot(test_acc_list, label='test acc')\n","    ax2.plot(train_acc_list, label='train acc')\n","    ax2.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HgmvbN86ryC","colab_type":"text"},"source":["# FINAL\n"]},{"cell_type":"code","metadata":{"id":"mOJBMusGk3k0","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","\n","import matplotlib.pyplot as plt\n","\n","class ResNetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResNetBlock, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.shortcut_is_needed = in_channels == out_channels\n","        if in_channels == out_channels:\n","            self.shortcut = nn.Identity()\n","            stride = 1\n","        else:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=(2, 2), stride=(2, 2), bias=False)\n","                #nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False)\n","                                          )\n","            stride = 2\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=(1, 1), bias=False),\n","            #nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=(1, 1), bias=False),\n","            #nn.BatchNorm2d(out_channels, affine=True, track_running_stats=False)\n","        )\n","        self.relu = nn.ReLU()\n","\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        return self.relu(self.block(x) + residual)\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, N=5):\n","        super(ResNet, self).__init__()\n","        layers = [nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n","        layers += [ResNetBlock(16, 16)] * N\n","        layers += [ResNetBlock(16, 32)] + [ResNetBlock(32, 32)] * (N - 1)\n","        layers += [ResNetBlock(32, 64)] + [ResNetBlock(64, 64)] * (N - 1)\n","        layers += [nn.AvgPool2d((8, 8))]\n","        self.decoder = nn.Linear(64, 10)\n","        self.layers = nn.Sequential(\n","            *layers\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = x.view(x.size(0), -1)\n","        return self.decoder(x)\n","\n","dummy = torch.ones((1, 3, 32, 32))\n","transform = transforms.Compose(\n","        [\n","            transforms.Pad((4, 4)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop(32),\n","            transforms.ToTensor()\n","        ]\n","    )\n","\n","#print(model)\n","#print(model(dummy).shape)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","CUDA = torch.cuda.device_count()\n","\n","def one_batch():\n","    model = ResNet(N=5)\n","    mean_train_losses = []\n","    mean_test_losses = []\n","    test_acc_list = []\n","    BS = 200\n","    trainset = torchvision.datasets.CIFAR10(\"CIFAR\", train=True, download=True, transform=transform)\n","    dl = DataLoader(trainset, batch_size=BS, shuffle=True)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","    epochs = 0\n","    epoch = 0\n","    images, labels = iter(dl).next()\n","\n","    device = 'cuda'\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    model.to(device)\n","\n","    print(images.element_size())\n","    print(labels.element_size())\n","\n","    accuracy = 0\n","    while accuracy < 100:\n","        epoch += 1\n","        model.train()\n","\n","        train_losses = []\n","        test_losses = []\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        print(\"outpus size\", outputs.element_size())\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_losses.append(loss.item())\n","\n","        correct = 0\n","        total = 0\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","        mean_train_losses.append(np.mean(train_losses))\n","\n","        accuracy = 100 * correct / total\n","        test_acc_list.append(accuracy)\n","        print('epoch : {}, train loss : {:.4f}, test loss : {:.4f}, test acc : {:.2f}%' \\\n","              .format(epoch + 1, np.mean(train_losses), np.mean(test_losses), accuracy))\n","\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n","    ax1.plot(mean_train_losses, label='train')\n","    # ax1.plot(mean_test_losses, label='test')\n","    lines, labels = ax1.get_legend_handles_labels()\n","    ax1.legend(lines, labels, loc='best')\n","\n","    ax2.plot(test_acc_list, label='test acc')\n","    ax2.legend()\n","    plt.show()\n","\n","\n","def train():\n","    model = ResNet(N=5)\n","    mean_train_losses = []\n","    mean_test_losses = []\n","    test_acc_list = []\n","    train_acc_list = []\n","    BS = 32\n","    trainset = torchvision.datasets.CIFAR10(\"CIFAR\", train=True, download=True, transform=transform)\n","    train_loader = DataLoader(trainset, batch_size=BS, shuffle=True)\n","    testset = torchvision.datasets.CIFAR10(\"CIFAR\", train=False, download=True, transform=transform)\n","    test_loader = DataLoader(testset, batch_size=BS, shuffle=False)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","    epochs = 200\n","    best_acc = 0\n","    PATH = \"drive/My Drive/resne32_t.pt\"\n","    # torch.save(model, PATH)\n","    # print(f\"Model was dumped to {PATH}\")\n","\n","    # model = torch.load(PATH)\n","    # model.eval()\n","    print(\"train started\")\n","    if CUDA:\n","        device = 'cuda'\n","        model.to(device)\n","    TRAIN = False\n","    for epoch in range(epochs):\n","        if TRAIN:\n","          model.train()\n","\n","          correct = 0\n","          total = 0\n","          train_losses = []\n","          test_losses = []\n","          for i, (images, labels) in enumerate(train_loader):\n","\n","              if CUDA:\n","                  images = images.to(device)\n","                  labels = labels.to(device)\n","\n","              optimizer.zero_grad()\n","\n","              outputs = model(images)\n","\n","              _, predicted = torch.max(outputs.data, 1)\n","              correct += (predicted == labels).sum().item()\n","              total += labels.size(0)\n","\n","              loss = loss_fn(outputs, labels)\n","              loss.backward()\n","              optimizer.step()\n","\n","              train_losses.append(loss.item())\n","\n","          t_accuracy = 100 * correct / total\n","          train_acc_list.append(t_accuracy)\n","          model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for i, (images, labels) in enumerate(test_loader):\n","                if CUDA:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","\n","                outputs = model(images)\n","                loss = loss_fn(outputs, labels)\n","\n","                test_losses.append(loss.item())\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                correct += (predicted == labels).sum().item()\n","                total += labels.size(0)\n","\n","        mean_train_losses.append(np.mean(train_losses))\n","        mean_test_losses.append(np.mean(test_losses))\n","\n","        accuracy = 100 * correct / total\n","        test_acc_list.append(accuracy)\n","        if accuracy > best_acc:\n","            torch.save(model, PATH)\n","            best_acc = accuracy\n","            print(f\"Model was dumped to {PATH}\")\n","        print('epoch : {}, train loss : {:.4f}, test loss : {:.4f}, train acc : {:.2f}%, test acc : {:.2f}%' \\\n","              .format(epoch + 1, np.mean(train_losses), np.mean(test_losses), t_accuracy, accuracy))\n","\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n","    ax1.plot(mean_train_losses, label='train')\n","    ax1.plot(mean_test_losses, label='test')\n","    lines, labels = ax1.get_legend_handles_labels()\n","    ax1.legend(lines, labels, loc='best')\n","\n","    ax2.plot(train_acc_list, label='train acc')\n","    ax2.plot(test_acc_list, label='test acc')\n","    ax2.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_vtxDoHlFP8","colab_type":"code","colab":{}},"source":["one_batch()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8djy-tkNldCp","colab_type":"code","colab":{}},"source":["train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a62Un44JhjmJ","colab_type":"text"},"source":["# RESNET 50\n"]},{"cell_type":"code","metadata":{"id":"qM5RLI7_hlvg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKSejNateofY","colab_type":"code","colab":{}},"source":["!wget ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wiLUyP1Cg5_S","colab_type":"code","colab":{}},"source":["!7z x Stanford_Online_Products.zip -o\"drive/My Drive\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P0ZtKt2xfN7w","colab_type":"text"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"C1rogbW-RULO","colab_type":"text"},"source":["# New Section"]}]}